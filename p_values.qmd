```{r}
library(tidyverse)
library(lubridate)
library(janitor)
```

## Testing Statistical Significance with P-values

### Are Maryland's WBB players shorter than other D-I teams' players?

```{r}
# Load the data

wbb_rosters <- read_csv("https://raw.githubusercontent.com/Sports-Roster-Data/womens-college-basketball/main/wbb_rosters_2023_24.csv") |> filter(!is.na(total_inches)) |> filter(division == 'I')

population_data <- wbb_rosters[sample(nrow(wbb_rosters), 100), ]

maryland <- wbb_rosters |> filter(ncaa_id == 392)
```

#### Define hypotheses

Null Hypothesis (H0): There is no significant difference in the average height of players on Maryland compared to the average height of a sample of players from the NCAA's Division I.

Alternative Hypothesis (H1): There is a significant difference in the average height of players on Maryland compared to the average height of a sample of players from the NCAA's Division I.


### The Formula

To calculate a t-test for significance, we need to use averages of the height of both the sample data (maryland) and the population (population_data), the standard deviation among our sample and the significance level or alpha, which is at the 95% confidence interval.

```{r}

# average Maryland height
mean(maryland$total_inches)

# average sample height
mean(population_data$total_inches)

# standard deviation among Maryland players
standard_deviation <- sd(maryland$total_inches)

# Set significance level
alpha <- 0.05

# Perform the hypothesis test
result <- t.test(x = maryland$total_inches, mu = mean(population_data$total_inches), sd = standard_deviation / sqrt(nrow(population_data)), alternative = "two.sided")

# Calculate p-value
p_value <- result$p.value

# Make a decision
if (p_value < alpha) {
  decision <- "Reject the null hypothesis, so there is a"
} else {
  decision <- "Fail to reject the null hypothesis, so there is no"
}

# Interpretation
interpretation <- paste("Based on the p-value of", round(p_value, 4),
                        ", at a significance level of", alpha,
                        ", we", decision, "statistically significant difference in the average height of Maryland players compared to a sample of all Division I players.")

interpretation

```

The key findings are:

  * The average height of Maryland players is **significantly higher** than the average height of the sampled Division I players.
  * This difference is statistically significant, meaning it is unlikely to have occurred by chance.

### Prince George's County Crime Data

```{r}
pg_crimes <- read_csv("https://raw.githubusercontent.com/dwillis/jour405_files/main/Crime_Incidents_July_2023_to_Present_20240414.csv") |> clean_names()

pg_crimes <- pg_crimes |> 
  mutate(clean_date = mdy_hms(date), month = month(clean_date), week_day = wday(clean_date))

pg_crimes |> 
  filter(str_detect(clearance_code_inc_type, "AUTO, STOLEN")) |> 
  group_by(month) |> 
  summarize(total = n())
```

### Stolen cars by month

Null Hypothesis: March's decline was not statistically significant and a result of random chance.
Alternative Hypothesis: March's decline was statistically significant.

### Set up our t.test

```{r}

# Load the data for all months from July through March, skipping April because it's not finished
car_thefts <- c(673, 596, 469, 525, 531, 551, 429, 451, 358)

# set the confidence interval
alpha <- 0.05

# Calculate the mean and standard deviation of all the months
all_months_mean <- mean(car_thefts)
all_months_sd <- sd(car_thefts)

# Perform the t-test
result <- t.test(car_thefts, mu = all_months_mean, alternative = "less")

# Print the results
print(result)

# Calculate p-value
p_value <- result$p.value

# Make a decision
if (p_value < alpha) {
  decision <- "Reject the null hypothesis"
} else {
  decision <- "Fail to reject the null hypothesis"
}

# Interpretation
interpretation <- paste("Based on the p-value of", round(p_value, 4),
                        ", at a significance level of", alpha,
                        ", we", decision)

interpretation
```

But wait, we didn't use the standard deviation in our t.test! Here's why:

    * When you have the entire data set, the t.test() function can calculate the necessary statistics (mean, standard deviation) internally.
    * Providing the standard deviation as a separate figure is only required when you want to use a hypothesized standard deviation, rather than estimating it from the sample data.

So, the t-test works with the full data set (car_thefts) because it can derive all the necessary statistics directly from the provided observations, without requiring the standard deviation as a separate input. If you are wondering, we didn't need to do the standard deviation for the Maryland players, either, because we have all of them (but it didn't hurt anything by adding it). Which is one more reason to calculate t-tests in R and not by hand. 


#### What about murders?

Null Hypothesis: There has been no significant change in murders this year.
Alternative Hypothesis: There has been a significant change in murders this year.

### Set up our data

```{r}
# Given data
pg_crimes |> 
  filter(month != 4) |>  # April isn't finished yet
  filter(clearance_code_inc_type == 'HOMICIDE') |> 
  group_by(month) |> 
  summarize(total = n())

# Set significance level
alpha <- 0.05

# Load the data from July through March
homicides <- c(6, 4, 5, 10, 4, 7, 5, 4, 7)

# Calculate the mean and standard deviation of the data
homicides_mean <- mean(homicides)
homicides_sd <- sd(homicides)

# Perform the t-test
results <- t.test(homicides, mu = homicides_mean)

# Print the results
print(results)

# Extract p-value
p_value <- results$p.value

# Make decision based on p-value
if (p_value < alpha) {
  decision <- "reject the null hypothesis"
} else {
  decision <- "fail to reject the null hypothesis"
}

decision

```
This result indicates that the variation in homicides across the 9 months, from July to March, is not statistically significant. The monthly homicide counts are not different from the overall mean of 5.77 in a statistically meaningful way. The t-test shows that the fluctuations in homicides during this time period are likely just due to random chance and do not represent a significant change or pattern in the data. The ranges for the 95 percent confidence interval show this; 7 is within that range.


### When we have a mean but not the actual times (like the homework!)

If we don't have the individual figures for a set, just the mean, then we can calculate the t-statistic another way, using the function `pt`. Let's say that we have the following scenario:

**Background**: Sarah, an amateur runner, usually runs a 5k (3.1 miles) race with an average time of 25.5 minutes. She has a standard deviation of 1.2 minutes in her past race timings.

**Intervention**: Her coach suggested that a new energy drink could help her run faster. Sarah decided to try the energy drink and recorded her race times for 15 subsequent 5k races.

**Data**: After using the new energy drink, Sarah’s mean time for these 15 races was 24.8 minutes.

**Objective**: Sarah’s coach thinks that the energy drink has significantly improved her running times. Perform a hypothesis test with a preset alpha of 0.05 to evaluate this claim, assuming the running times are normally distributed.

```{r}
# Define the sample data
sample_mean <- 24.8
hypothesized_mean <- 25.5
sample_std_dev <- 1.2
sample_size <- 15

# Calculate the t-statistic
t_statistic <- (sample_mean - hypothesized_mean) / (sample_std_dev / sqrt(sample_size))

# Calculate the degrees of freedom
degrees_of_freedom <- sample_size - 1

# Calculate the p-value for a one-tailed test (left-tailed)
p_value <- pt(t_statistic, df = degrees_of_freedom)

# Display the results: t-statistic and p-value
t_statistic
p_value


```

If the p-value is less than 0.05, it indicates that there is statistically significant evidence to reject the null hypothesis, suggesting that the energy drink helps Sarah run faster. In this case, there is.
